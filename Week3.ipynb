{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbFCfCbu+/knIUErwslgkd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andylee50609/data-course-sample/blob/main/Week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "參數宣告"
      ],
      "metadata": {
        "id": "ykVIB5wtzblT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise import KNNBasic"
      ],
      "metadata": {
        "id": "jXmh6B-azvvC",
        "outputId": "451d1e14-1b2b-4884-b75b-6f1f9189de68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-439cd4c97d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNNBasic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "資料讀取"
      ],
      "metadata": {
        "id": "Gd4t7EKwzbhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = pd.read_json('meta_All_Beauty.json.gz', lines = True)[['asin', 'title', 'description', 'rank', 'brand']]\n",
        "ratings = pd.read_csv('All_Beauty.csv', names=['asin', 'reviewerID', 'overall', 'unixReviewTime'], header = None)\n",
        "ratings['DATE'] = pd.to_datetime(ratings['unixReviewTime'], unit='s')\n",
        "\n",
        "# 取近期的資料較有參考價值\n",
        "ratings = ratings[ratings['DATE'] >= \"2016-09-01\"]"
      ],
      "metadata": {
        "id": "njdovZNNzwLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "資料前處理"
      ],
      "metadata": {
        "id": "yDufV_f7zbcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Data Clean ========\n",
        "\n",
        "# 補充討論熱度及評分資訊\n",
        "tmp = ratings[[\"asin\",\"overall\"]].groupby(\"asin\").agg({'asin':'size', 'overall':'mean'}).rename(columns={'asin':'reviewNum','overall':'meanScore'}).reset_index()\n",
        "metadata = pd.merge(metadata, tmp, on=\"asin\", how =\"inner\").fillna(0)\n",
        "ratings = pd.merge(ratings, tmp, on=\"asin\", how =\"inner\").fillna(0)\n",
        "\n",
        "# 補充商品子類別資訊\n",
        "metadata['sub_category'] = metadata['rank'].str.split(\"in \").str[1].replace(r'&amp;','&', regex = True).replace(r'\\(','', regex = True)\n",
        "metadata = metadata.drop(columns = [\"rank\"])\n",
        "metadata['brand']= metadata['brand'].str.replace('#','').replace('\\(','',regex=True).replace('\\)','',regex=True).replace(',','',regex=True).replace('-','',regex=True).replace('\\.','',regex=True).replace('\\'','',regex=True).replace('\\*','',regex=True).replace('', np.nan)\n",
        "rule_based_recom = metadata[metadata[\"reviewNum\"]>=300][[\"asin\",\"meanScore\"]].sort_values(\"meanScore\", ascending = False).drop_duplicates()\n",
        "\n",
        "# ========Testing/Training Set========\n",
        "\n",
        "# 訓練資料(20180901前的交易)\n",
        "ratings_trainings = ratings[(ratings['DATE'] < '2018-09-01')]\n",
        "\n",
        "# 測試資料(20180901-20180930的交易)\n",
        "ratings_testings = ratings[\n",
        "    (ratings['DATE'] >= '2018-09-01') & \n",
        "    (ratings['DATE'] <= '2018-09-30')]\n",
        "\n",
        "# groupby[reviewerID],將結果存成list並建成字典\n",
        "ratings_testings_by_user = ratings_testings.groupby('reviewerID').agg(list).reset_index()[['reviewerID', 'asin']].to_dict('records')\n",
        "ratings_testings_by_user = { rating['reviewerID']: rating['asin'] for rating in ratings_testings_by_user }\n",
        "users = list(ratings_testings_by_user.keys())\n",
        "\n",
        "\n",
        "# ======== 結構化資料處理(sub_category、brand) ========\n",
        "# 將subCat轉成稀疏矩陣\n",
        "dummy_subCat = pd.get_dummies(metadata['sub_category'] , columns = ['subcat'])\n",
        "\n",
        "# 將brand轉成稀疏矩陣\n",
        "dummy_brand = pd.get_dummies(metadata['brand'] , columns = ['brand'])\n",
        "\n",
        "# ======== 非結構化資料處理(title、description) ========\n",
        "\n",
        "# 把 description 從 list 轉為 str\n",
        "metadata['description'] = metadata['description'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "#將 title 與 description 合併\n",
        "metadata['title_description'] = metadata['title'] + metadata['description']\n",
        "metadata['title_description'] = metadata['title_description'].str.lower()"
      ],
      "metadata": {
        "id": "vCogUt3wzwm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "產生推薦：CF(User Based)"
      ],
      "metadata": {
        "id": "VC5KEp82zbX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommender_user_based(training_data, rule_based, users=[], k=10):\n",
        "\n",
        "    # loading data from dataframe\n",
        "    # user_to_items dict:\n",
        "    # {\n",
        "    #   'user': {\n",
        "    #       'item': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    user_to_items = defaultdict(dict) # 製作出雙層迴圈：user-item-rating\n",
        "    for _, row in training_data.iterrows(): # 對一列列進行迭代\n",
        "        row = dict(row) # 迭代出的每列變成dic\n",
        "        user = row['reviewerID'] # key值填入'reviewerID'\n",
        "        item = row['asin']\n",
        "        rating = float(row['overall'])\n",
        "\n",
        "        user_to_items[user][item] = rating # 雙層字典結構\n",
        "\n",
        "    # print(\"total users before filtering: \", len(user_to_items))\n",
        "\n",
        "    # remove obscure user to decrease data size\n",
        "    # filtering params\n",
        "    remove_obscure_user = True # 當作開關使用，若設為 False，擇不會進行資料篩選\n",
        "    user_rating_threshold = 3\n",
        "    all_users = list(user_to_items.keys())\n",
        "    for user in all_users:\n",
        "        ratings = user_to_items[user]\n",
        "        if remove_obscure_user and len(ratings) < user_rating_threshold:\n",
        "            del user_to_items[user]\n",
        "\n",
        "    # print(\"total users  after filtering: \", len(user_to_items))\n",
        "\n",
        "    # generate item to user mapping dict\n",
        "    # {\n",
        "    #   'item': {\n",
        "    #       'user': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    item_to_users = defaultdict(dict)\n",
        "    for user, items in user_to_items.items(): # 雙層迴圈把user, item, rating都取出->轉置\n",
        "        for item, rating in items.items():\n",
        "            item_to_users[item][user] = rating\n",
        "\n",
        "    # prepare data of computing user similarity \n",
        "    init_sim = lambda: [0 for _ in range(3)] # 透過兩次lambda傳入，設置出 user1、user2的初始 [0,0,0]\n",
        "    factory = lambda: defaultdict(init_sim)\n",
        "    pre_user_similarity = defaultdict(factory)\n",
        "    n = len(item_to_users)\n",
        "    index = 0\n",
        "    for item, user_ratings in item_to_users.items():\n",
        "        if len(user_ratings) > 1:\n",
        "            # print(f\"item: {item} have been rated by {len(user_ratings)} users progress: {index}/{n}\")\n",
        "            for user1, user2 in combinations(user_ratings.keys(), 2): #兩兩一組 排列組合\n",
        "                xy = user_ratings[user1] * user_ratings[user2]\n",
        "                xx = user_ratings[user1] ** 2\n",
        "                yy = user_ratings[user2] ** 2\n",
        "                pre_user_similarity[user1][user2][0] += xy    # [xy,xx,yy]\n",
        "                pre_user_similarity[user1][user2][1] += xx\n",
        "                pre_user_similarity[user1][user2][2] += yy\n",
        "                # 走過每一個 item，得到每一個 item 有哪一些 user 對它評分，之後產生所有 user 的倆倆組合，計算 xy, xx, yy 之後填入\n",
        "                pre_user_similarity[user2][user1][0] += xy\n",
        "                pre_user_similarity[user2][user1][1] += xx\n",
        "                pre_user_similarity[user2][user1][2] += yy\n",
        "        index += 1\n",
        "\n",
        "    user_similarity = {}\n",
        "    for src_user in pre_user_similarity:\n",
        "        user_similarity_order = []\n",
        "        for dst_user, val in pre_user_similarity[src_user].items(): # break出來後到這邊\n",
        "            xy = val[0]\n",
        "            xx = val[1]\n",
        "            yy = val[2]\n",
        "            div = ((xx*yy) ** 0.5) # 開平方根\n",
        "            if div == 0: # \n",
        "                continue\n",
        "            similarity = xy / div\n",
        "            if similarity < 0:  # 小於0者排除\n",
        "                continue\n",
        "            for i, s in enumerate(user_similarity_order): #s-tuple # 實現sort\n",
        "                target_similarity = s[1] # \n",
        "                if target_similarity < similarity:\n",
        "                    user_similarity_order.insert(i, (dst_user, similarity))\n",
        "                    break\n",
        "            else: # 迴圈中沒有執行break(完整跑完)，就會執行這段  ##(待更新)當第一個抓到的數字是最小，\n",
        "                user_similarity_order.append((dst_user, similarity))\n",
        "        user_similarity[src_user] = user_similarity_order # list中tuple\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users: #testing data中的user\n",
        "        if user in user_similarity:\n",
        "            sim_users = user_similarity[user]\n",
        "            recommended_items = []\n",
        "            recommended_items_set = set()\n",
        "            user_have_rated = set(user_to_items[user]) # 同產品不同評分 去重複(只想確定他有評分、不管評分高低)\n",
        "            stop_recommend = False\n",
        "            # 迴圈看 相似度陣列裡所有的使用者\n",
        "            for sim_user, _ in sim_users:#97行的 跑相似度中的tuple取出\n",
        "                # 按照 rating 去排序 [item:rating,...]\n",
        "                items_from_sim_user = sorted(list(user_to_items[sim_user].items()), key=lambda item: item[1]) #抓最相似的使用者，在u2i中評過的item針對dict中value小到大排序\n",
        "                for item, _ in items_from_sim_user: # _是rating(不重要的變數以底線代之)\n",
        "                    # 如果商品之前該使用者為買過 且尚不在推薦名單內\n",
        "                    if item not in user_have_rated and item not in recommended_items_set: #只取用戶沒評過的產品(評過代表買過)\n",
        "                        recommended_items.append(item)\n",
        "                        recommended_items_set.add(item)\n",
        "                    if len(recommended_items) >= k:\n",
        "                        stop_recommend = True # TRUE跳出\n",
        "                        break\n",
        "                if stop_recommend:\n",
        "                    break # 結束新增商品 (推薦完畢)\n",
        "            recommendation[user] = recommended_items\n",
        "        else: # 不在那38位中\n",
        "            recommendation[user] = []\n",
        "    \n",
        "    # 使用Rule-Based\n",
        "    if rule_based == True:\n",
        "        for i in recommendation.keys():\n",
        "            if recommendation[i] == []:\n",
        "                recommendation[i] = list(rule_based_recom[\"asin\"][:k]) # 輔以rule-based進行推薦\n",
        "            \n",
        "    return recommendation\n",
        "\n",
        "ratings_by_user_based = recommender_user_based(ratings_trainings, True, users)"
      ],
      "metadata": {
        "id": "u34QEcd9zw-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "產生推薦：CF(Item Based)"
      ],
      "metadata": {
        "id": "WbWOaKAezbRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommender_item_based(training_data, rule_based, users=[], k=10):\n",
        "\n",
        "    # loading data from dataframe\n",
        "    # item_to_users dict:\n",
        "    # {\n",
        "    #   'item': {\n",
        "    #       'user': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    item_to_users = defaultdict(dict)\n",
        "    for _, row in training_data.iterrows():\n",
        "        row = dict(row)\n",
        "        user = row['reviewerID']\n",
        "        item = row['asin']\n",
        "        rating = float(row['overall'])\n",
        "        item_to_users[item][user] = rating\n",
        "\n",
        "    user_to_items = defaultdict(dict)\n",
        "    for item, rating_users in item_to_users.items():\n",
        "        for user, rating in rating_users.items():\n",
        "            user_to_items[user][item] = rating\n",
        "\n",
        "    init_sim = lambda: [0, 0, 0]\n",
        "    factory = lambda: defaultdict(init_sim)\n",
        "    pre_item_similarity = defaultdict(factory)\n",
        "    for user, items in user_to_items.items():\n",
        "        if len(items) > 1:\n",
        "            for i1, i2 in combinations(items.keys(), 2):\n",
        "                xy = items[i1] * items[i2]\n",
        "                xx = items[i1] ** 2\n",
        "                yy = items[i2] ** 2\n",
        "                pre_item_similarity[i1][i2][0] += xy\n",
        "                pre_item_similarity[i1][i2][1] += xx\n",
        "                pre_item_similarity[i1][i2][2] += yy\n",
        "\n",
        "                pre_item_similarity[i2][i1][0] += xy\n",
        "                pre_item_similarity[i2][i1][1] += xx\n",
        "                pre_item_similarity[i2][i1][2] += yy\n",
        "\n",
        "    item_similarity = {}\n",
        "    for src_item in pre_item_similarity:\n",
        "        item_similarity_order = []\n",
        "        for dst_item, val in pre_item_similarity[src_item].items():\n",
        "            xy = val[0]\n",
        "            xx = val[1]\n",
        "            yy = val[2]\n",
        "            div = ((xx*yy) ** 0.5)\n",
        "            if div == 0:\n",
        "                continue\n",
        "            similarity = xy / div\n",
        "            if similarity < 0:\n",
        "                continue\n",
        "            for i, s in enumerate(item_similarity_order):\n",
        "                target_similarity = s[1]\n",
        "                if target_similarity < similarity:\n",
        "                    item_similarity_order.insert(i, (dst_item, similarity))\n",
        "                    break\n",
        "            else:\n",
        "                item_similarity_order.append((dst_item, similarity))\n",
        "        item_similarity[src_item] = item_similarity_order\n",
        "\n",
        "    # print(f\"get {k} recommendation items for for user: {users}\")\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items = []\n",
        "        items_set = set()\n",
        "        stop = False\n",
        "        user_has_rated = set(user_to_items[user])\n",
        "        for item in user_has_rated:\n",
        "            if item in item_similarity:\n",
        "                for sim_item, _ in item_similarity[item]:\n",
        "                    # skip the item user has rated\n",
        "                    if sim_item not in user_has_rated and sim_item not in items_set:\n",
        "                        items.append(sim_item)\n",
        "                        items_set.add(sim_item)\n",
        "                    if len(items) >= k:\n",
        "                        stop = True\n",
        "                        break\n",
        "                if stop:\n",
        "                    break\n",
        "        recommendation[user] = items\n",
        "        \n",
        "    # 使用Rule-Based\n",
        "    if rule_based == True:\n",
        "        for i in recommendation.keys():\n",
        "            if recommendation[i] == []:\n",
        "                recommendation[i] = list(rule_based_recom[\"asin\"][:k]) # 輔以rule-based進行推薦\n",
        "\n",
        "    return recommendation    \n",
        "\n",
        "ratings_by_item_based = recommender_item_based(ratings_trainings, True, users)"
      ],
      "metadata": {
        "id": "VQ_R-9__zxOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "產生推薦：CF(surprise)"
      ],
      "metadata": {
        "id": "KOEPo4glzsPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommender_surprise(training_data, rule_based, users=[], k=10, user_based=False, algo=KNNBasic):\n",
        "\n",
        "    training_data = (\n",
        "        training_data\n",
        "        .sort_values(\"DATE\", ascending=False)\n",
        "        .groupby(['reviewerID', 'asin']).head(1)\n",
        "    )\n",
        "\n",
        "    reader = Reader(rating_scale=(0, 5))\n",
        "    training_data = training_data[['reviewerID', 'asin', 'overall']]\n",
        "    data = Dataset.load_from_df(training_data, reader=reader)\n",
        "\n",
        "    sim_options = {\n",
        "        'name': 'cosine',\n",
        "        'user_based': user_based  # compute similarities between items\n",
        "    }\n",
        "    algo_impl = algo(sim_options=sim_options)\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo_impl.fit(trainset)\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items_user_rated = set(training_data.loc[training_data['reviewerID'] == user]['asin'].to_list())\n",
        "        recommend_item_list = []\n",
        "        recommend_item_set = set()\n",
        "        for item in items_user_rated:\n",
        "            iid = algo_impl.trainset.to_inner_iid(item)\n",
        "            recommend_items_iid = algo_impl.get_neighbors(iid, k)\n",
        "            for sim_item_iid in recommend_items_iid:\n",
        "                item_raw_id = algo_impl.trainset.to_raw_iid(sim_item_iid)\n",
        "                if item_raw_id not in items_user_rated and item_raw_id not in recommend_item_set:\n",
        "                    recommend_item_list.append(item_raw_id)\n",
        "                    recommend_item_set.add(item_raw_id)\n",
        "\n",
        "            if len(recommend_item_list) >= k:\n",
        "                recommend_item_list = recommend_item_list[:k]\n",
        "                break\n",
        "        recommendation[user] = recommend_item_list\n",
        "\n",
        "    # 使用Rule-Based\n",
        "    if rule_based == True:\n",
        "        for i in recommendation.keys():\n",
        "            if recommendation[i] == []:\n",
        "                recommendation[i] = list(rule_based_recom[\"asin\"][:k]) # 輔以rule-based進行推薦\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "ratings_by_surprise = recommender_surprise(ratings_trainings, True, users)"
      ],
      "metadata": {
        "id": "GA-tCKQdzxlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果評估"
      ],
      "metadata": {
        "id": "JTB-ZJcmzt62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(ratings_testings_by_user={}, ratings_by_user={}, method=None):\n",
        "    '''\n",
        "    * ratings_testings_by_user: dict 真實被購買的商品資料（2018-09-01 以後資料）\n",
        "    * ratings_by_user: dict 利用訓練資料學習的推薦商品\n",
        "    * method: str\n",
        "    * score: float\n",
        "    '''\n",
        "    total = 0\n",
        "    for d in ratings_testings_by_user:\n",
        "        if d in ratings_by_user:\n",
        "            total += len(set(ratings_by_user[d]) & set(ratings_testings_by_user[d]))\n",
        "\n",
        "    score = total / len(ratings_testings)\n",
        "    return score\n",
        "\n",
        "\n",
        "print(evaluate(ratings_testings_by_user, ratings_by_user_based))\n",
        "\n",
        "# 手刻版本，推薦準確率：0 % (Traning Data：2017/9-2018/8)\n",
        "# 手刻版本，推薦準確率：0 % (Traning Data：2016/9-2018/8)\n",
        "\n",
        "# 加上rule-based，推薦準確率：9.83% (Traning Data：2017/9-2018/8)\n",
        "# 加上rule-based，推薦準確率：1.35% (Traning Data：2016/9-2018/8)\n",
        "\n",
        "print(evaluate(ratings_testings_by_user, ratings_by_item_based))\n",
        "\n",
        "# 手刻版本，推薦準確率：0 % (Traning Data：2017/9-2018/8)\n",
        "# 手刻版本，推薦準確率：0 % (Traning Data：2016/9-2018/8)\n",
        "\n",
        "# 加上rule-based，推薦準確率：9.66% (Traning Data：2017/9-2018/8)\n",
        "# 加上rule-based，推薦準確率：1.35% (Traning Data：2016/9-2018/8)\n",
        "\n",
        "print(evaluate(ratings_testings_by_user, ratings_by_surprise))\n",
        "\n",
        "# # 純套用surprise，推薦準確率：0.17 % (Traning Data：2017/9-2018/8)\n",
        "# # 純套用surprise，推薦準確率：0 % (Traning Data：2016/9-2018/8)\n",
        "\n",
        "# # 加上rule-based，推薦準確率：9.83% (Traning Data：2017/9-2018/8)\n",
        "# # 加上rule-based，推薦準確率：1.35% (Traning Data：2016/9-2018/8)\n",
        "    "
      ],
      "metadata": {
        "id": "N_C9pbWazaiP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}